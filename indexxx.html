<html>
    <head>
        <link rel="stylesheet" href="./style/style.css">
    </head>
       <body> 
        <h2><strong>ArrayPool: подводные камни</strong></h2>
        <h2>Салам алейкум</h2>
<img src="https://habrastorage.org/r/w1560/webt/8_/s5/ga/8_s5gatztbsosbcwq_toejwgf7w.jpeg" alt="">
<p>Автоматическая сборка мусора упрощает разработку программ, избавляя от <br>необходимости отслеживать жизненный цикл объектов и удалять их вручную. Однако, чтобы сборщик мусора был <br>полезным инструментом, а не главным врагом на пути к высокой производительности — иногда <br>имеет смысл помогать ему, оптимизируя частые аллокации и аллокации больших объектов.</p>

    <p>Для уменьшения аллокаций в современном .NET предусмотрены Span/Memory<T>, stackalloc<br>с поддержкой Span, структуры и другие средства. Но если без объекта в куче не обойтись,<br>например, если объект слишком большой для стека, или используется в асинхронном коде — этот<br>объект можно переиспользовать. И для самых крупных объектов — массивов, в .NET встроены<br>несколько реализаций ArrayPool<T>.</p>

<p>В этой статье я расскажу о внутреннем устройстве реализаций ArrayPool<T> в .NET, о<br>подводных камнях, которые могут сделать пулинг неэффективным, о concurrent-структурах<br>данных, а также о пулинге объектов, отличных от массивов.</p>


<h3>Allocator vs Pool</h3>

<div>
    Пул можно рассматривать как аллокатор объектов. У них одинаковый интерфейс с двумя<br>методами, выполняющими функции new и delete. Хорошая реализация нативного аллокатора<br>также переиспользует память: при delete участок памяти не сразу отдаётся операционной<br>системе обратно, а переиспользуется для новых объектов внутри программы, т.е. работает как<br>пул.
</div>

<p>Возникает вопрос, зачем делать пул managed-объектов, вместо перехода на нативный<br>аллокатор</p>

<ul>
    <li><p>
        Это требует меньших изменений в коде, который эти объекты использует. Также, некоторые<br>API принимают ArraySegment<T>, а не Memory<T></T>
    </p></li>
    <li><p>
        Это помогает сохранить код кроссплатформенным. Использование стороннего аллокатора<br>обычно предполагает подключение нативной библиотеки.
    </p></li>
    <li><p>
        Managed-объекты могут иметь ссылки на другие managed-объекты. Ссылаться на managed-<br>объекты из памяти, которой не управляет сборщик мусора нельзя — при дефрагментации<br>кучи и перемещении объектов такие ссылки не будут обновлены и станут невалидными.
    </p></ul>
</ol>


<p>Отличие пула от аллокатора в том, что пулу можно не сохранять часть объектов, например, при<br>превышении вместимости — тогда их соберёт сборщик мусора. Аллокатор же должен<br>гарантировать отсутствие утечек памяти.</p>

<h3>ArrayPool</h3>

<div>В .NET встроены две разные реализации абстрактного класса ArrayPool<T>. Т.к. невозможно</div>
<div>сохранить массивы для каждого из размера по-отдельности (их будет слишком много), при вызове</div>
<div>.Rent(N) пул возвращает массив размера N или больше. Внутри пул хранит массивы с</div>
<div>длинами, равными степеням двойки.</div>

<p>

<div>Первая — для пулов, создающихся с помощью</div>
<div>ArrayPool.Create()/ArrayPool.Create(maxArrayLength, maxArraysPerBucket)</div>
<div>Вторая — статический ArrayPool<T>.Shared. Также можно сделать свою реализацию</div>
<div>ArrayPool</div>

</p>

<div>Разбор отличий пулов, добываемых через ArrayPool<T>.Shared и</div>
<div>ArrayPool<T>.Create(...) начнём с бенчмарка. Кроме этих реализаций, протестируем также</div>
<div>реализацию, которая ничего не переиспользует, а просто аллоцирует новые массивы и бросает их</div>
<div>на совесть GC</div>

<hr>

    <div>// Threads = 16</div>
    <div> // Iterations = 64*1024</div>
    <div> // ArraySize = 1024</div>
    <div> [Benchmark]</div>
    <div> public void ArrayPoolConcurrent()</div>
    <div> {</div>
        <div>  var tasks = new Task[Threads];</div>
        <div> for (int i = 0; i  Threads; i++)</div>
        <div> {</div>
            <div>  tasks[i] = Task.Run(() =></div>
            <div> {</div>
                <div>   for (int j = 0; j  Iterations; j++)</div>
                <div>  {</div>
                    <div>    var arr = pool.Rent(ArraySize);</div>
    <p>
        <div>   // имитация использования массива сложностью O(ArraySize)</div>
        <div>  // не просто так же он нам нужен, чтобы сразу вернуть в пул?</div>
        <div> Random.Shared.NextBytes(arr);</div>
        <div> pool.Return(arr);</div>
  <div> }</div>
              <div> });</div>
  <div> }</div>
        <div> Task.WaitAll(tasks);</div>
      <div> }</div>

    <hr>
   <div> |      Pool |        Mean |     Allocated |</div> 
   <div>|----------:|------------:|--------------:|</div> 
   <div>|    Create |   170.09 ms |       2.77 KB |</div> 
   <div>|    Shared |    14.96 ms |       2.41 KB |</div> 
   <div>|       new |    69.77 ms | 1072085.02 KB |</div> 
   
   <p>
     <div>Код, не связанный с работой с пулом занимает ~13 ms, что было замерено отдельно.</div>
<p>
<div>Пул, созданный через ArrayPool<byte>.Create() оказался медленнее даже аллокации</div>
    <div>(оператора new), и гораздо медленнее ArrayPool<byte>.Shared (за вычетом оверхеда). Но не</div>
        <div>торопитесь делать выводы по одному бенчмарку, тестирующему лишь частный случай, и</div>
        <div>списывать эту реализацию пула — далее мы разберёмся, как эти пулы устроены внутри, и почему</div>
        <div>результат получился таким</div>

<p>
    <div>   Отмечу, что пул — лишь вспомогательный компонент, и бенчмаркать нужно алгоритм или сервис,</div>
    <div>в котором пул используется — сравнивать, улучшилась ли производительность от</div>
    <div>переиспользования объектов. Да и самая быстрая реализация пулинга — та, которая не содержит</div>
    <div>никакой синхронизации с другими потоками. В однопоточном коде проще сохранить массив в поле</div>
    <div>класса и всегда использовать его, без всяких пулов. А если нужно хранить несколько объектов в</div>
    <div>однопоточном алгоритме, то подойдут обычные Queue<T>/Stack<T>.</div>

<p>


    <h3>ArrayPool<T>.Create()</h3>
        
<p>

<img src="https://habrastorage.org/r/w1560/webt/er/f3/a8/erf3a8yozvmkv62m-x6k7embpbw.png" alt="">

<p>

    <div>Методы .Create() и .Create(maxArrayLength, maxArraysPerBucket)создают</div>
   <div>ConfigurableArrayPool<T>. Здесь нужно быть осторожным — значение максимальной длины</div>
    <div>массива в этом пуле по умолчанию — всего лишь 1024 * 1024, при её превышении массивы</div>
    <div>будут аллоцироваться и не сохраняться в пуле. Поэтому, если ArrayPool создаётся для</div>
    <div>больших массивов — параметры придётся переопределить.</div>
    
<p>


    <div>Реализация ConfigurableArrayPool<T> очень проста:</div>

        <ul>
            <li>
                массивы в пуле сгруппированы по размерам (размер — всегда степень двойки)
            </li>
            <li>
                массивы одного размера хранятся в списке (на основе массива)
            </li>
            <li>
                каждый список защищён от многопоточного доступа с помощью SpinLock
            </li>
        </ul>

<p>

<div>Как раз из-за блокировки эта реализация пула не масштабируется на множество потоков. В итоге</div>
<div>основным её применением становятся большие массивы, в случае с которыми время работы с</div>
<div>пулом пренебрежимо мало по сравнению с обработкой данных, которыми эти массивы</div>
<div>заполняются.</div>

<p>

<h2>ArrayPool<T>.Shared</h2>

    <img src="https://habrastorage.org/r/w1560/webt/rm/fl/uv/rmfluvevzxjjkjwm1x5c5s_3fxo.png" alt="">

<p>

    <div>  Это статический пул, разделяемый всем кодом в программе. Реализация называется</div>
    <div>TlsOverPerCoreLockedStacksArrayPool<T> и на данный момент, никаких настроек не имеет.</div>
    <div>Максимальный размер массива в пуле — 2^30 элементов. Tls в названии значит</div>
    <div>ThreadLocalStorage, исходя из этого можно догадаться, за счёт чего этот пул работает быстро</div>
    <div>в многопоточной среде.</div>

    <p>

        <div>В этом пуле реализовано двухуровневое хранение объектов. Первый уровень — локальный набор</div>
        <div>массивов для каждого потока. Хранится в [ThreadStatic] поле. Доступ к локальной части пула</div>
      <div>не требует синхронизации с другими потоками. Однако, локально хранится максимум по одному</div>  
      <div>массиву каждого размера. Использование статического поля здесь возможно, т.к. пул глобальный,</div>
      <div>т.е. создаётся в единственном экземпляре. В нестатическом пуле для этой оптимизации придётся</div>
      <div>использовать ThreadLocal.</div>
      
      <p>

        <div>Второй уровень — разделяемый между потоками. Но в отличие от ConfigurableArrayPool<T>,</div>
            <div>для каждого размера хранится не один список массивов, а несколько — по количеству логических</div>
            <div>ядер (max. 64), каждый из списков защищён отдельной блокировкой. Это снижает конкуренцию</div>
            <div>между потоками — теперь они идут под разные блокировки, а не под одну. Вместо SpinLock в</div>
            <div>реализации Shared пула используется обычный lock/Monitor.</div>

<p>

    <h2>Speed — Memory tradeoff</h2>

    <div>Оптимизация с thread local слотом имеет свою цену: в пуле может скопиться большое количество</div>
    <div>крупных массивов, раздувая память приложения. В примере ниже первый поток создаёт новый</div>
    <div>массив и возвращает его в пул. Этот массив попадает в Thread Local слот первого потока. В итоге,</div>
    <div>при попытке получить массив того же размера из другого потока — переиспользования не</div>
    <div>произойдёт и будет выделен новый массив. В итоге для больших массивов может быть выгоднее</div>
    <div>использовать реализацию пула с общим набором объектов для всех потоков.</div>

<p>
    <div>// thread 1</div>
    <div>  var pool = ArrayPool<long>.Shared;</div>
        <div> var arr1 = pool.Rent(1024*1024*1024);</div>
        <div>  pool.Return(arr1);</div>
        <p>
            <div> Task.Run(() =></div>
            <div>  {</div>
            <div>    // thread 2</div>
            <div> var arr2 = pool.Rent(1024 * 1024 * 1024);</div>
            <div>  Console.WriteLine(arr1 == arr2);</div>
            <div>  }).Wait();</div>

<h2>Очистка памяти при GC</h2>

<div>Отчасти для решения предыдущей проблемы, в ArrayPool<T> предусмотрена очистка памяти</div>
    <div>при сборке мусора. С помощью хака с финализатором пул узнаёт о срабатываниях сборщика</div>
    <div>мусора и периодически выбрасывает избыток массивов, помогая освободить память.</div>
<p>
    <div>Не всегда это поведение желательное. Преждевременное удаление больших массивов,</div>
    <div>находящихся в Large Object Heap, может привести к излишней фрагментации кучи. Это ещё один</div>
    <div>повод задуматься об использовании другого механизма для переиспользования больших</div>
    <div>массивов.</div>

    <h2>Штраф за невозврат массива в пул</h2>

    <div>Бенчмарк, с которого мы начали, в случае ArrayPool<T>.Shared "пробивает" только первый</div>
        <div>уровень пулинга — thread local. Возникает вопрос, насколько производителен второй уровень —</div>
        <div>per core locked stacks, особенно учитывая то, что в нём есть блокировка. Для замера, сделаем</div>
        <div>бенчмарк, использующий сразу два массива из пула.</div>

        <h4>Код бенчмарка</h4>

        <div>|      Pool |        Mean |      Allocated |</div>
        <div>   |----------:|------------:|---------------:|</div>
        <div>  | Allocator |      138 ms |  2146306.76 KB |</div>
        <div>   |    Create |      230 ms |        2.88 KB |</div>
        <div>   |    Shared |       33 ms |        2.53 KB |</div>
        
<p>
        <div>Нагрузка, не связанная с пулом, заняла 24 ms — второй уровень Shared пула уже не бесплатен</div>
         <div>но пул по прежнему достаточно производителен — это достигается за счёт того, что потоки в</div>
         <div>бенчмарке берут массивы из разных списков и захватывают разные блокировки — contention не возникает.</div>
         <div>возникает.</div>

<p> 

          <div>Каждый поток не всегда использует только один список. Если при .Rent(N) подходящий массив</div>
<div>не был найден в "своём" списке, то по кругу обходятся все остальные, лишь после этого</div>
<div>аллоцируется новый массив. И если не возвращать массивы в пул обратно, то каждый вызов</div>
<div>.Rent(N) будет по очереди захватывать все блокировки, приводя к большому contention.</div>

<p>

    <div>  |            Pool |        Mean | Lock Contentions |     Allocated |</div>
    <div>|----------------:|------------:|-----------------:|--------------:|</div>
    <div>|       Allocator |      138 ms |                - | 2146306.76 KB |</div>
    <div>|          Shared |       33 ms |                - |       2.53 KB |</div>
    <div>| Shared_NoReturn |      968 ms |        3666.6667 | 2144145.85 KB |</div>

    <p>

        <div> От этой проблемы есть некоторая "защита". Второй уровень пула (PerCoreLockedStacks)</div>
        <div>инициализируется только при первом возврате массива в него. Если нигде в программе массивы</div>
        <div>не возвращаются в пул, то .Rent(N) будет аллоцировать новый массив без захвата блокировок.</div>

        <p>

            <div>Также, вместимость Shared пула относительно небольшая — 8 массивов каждого размера в</div>
            <div>каждом PerCoreLockedStacks (т.е. 512 на размер максимум). И если требуется много массивов,</div>
            <div>каждый из которых будет использоваться долгосрочно — эффекта от пулинга не будет, т.к.</div>
            <div>неизбежно будут создаваться новые массивы, а потоки будут обходить блокировки в надежде </div>
            <div>найти хоть что-то в опустошенном пуле.</div>

            <h2>Диагностики</h2>

            <div></div>








</p>






    </body>
</html>

